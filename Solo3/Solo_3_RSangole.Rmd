---
title: "450 - Marketing Analytics - Solo 3"
author: 'R Sangole'
fontsize: 10pt
output:
  pdf_document: 
    df_print: kable
    highlight: tango
    toc: no
  html_notebook: default
urlcolor: blue
---

# Methodology Discussion

The input data for this modeling exercise is a combination of aggregated customer transaction history data, customer profile information, customer preference information and also demographic data for each zipcodes. The input data is large dataset (30779 rows, each for an individual customer) and 554 variables (numerical and categorical combined).

# Data Preparation

The data required significant pre-preparation before modeling could be done. To summarize the data preparation steps taken:

- Factor variables with `NA` and `U` (Unknown) levels are both re-labeled at `U`
- Numerical variables originally as characters or factors are typecasted appropriately
- Factor variables with either very large number of levels, or with certain levels contributing to very small percentage of the overall data (1% or less) are re-leveled, i.e. levels with very small number of variables are grouped together into `Other`
- Variables with near zero variance are removed. These are identified using the `caret::nearZeroVar()` call. Fully zero variance calls are also removed using this function.
- New variables are created based on the originals. Brief description 
    * cusum_resp_till15 : How many times has the customer responded in the past, till campaign 15?
    * cusum_qty_till15 : How much has the customer purchased in the past, till campaign 15?
    * cusum_tot_usd_till15 : How much has the customer spent in the past, till campaign 15?
    * cusum_tot_usd_12_to_15 : How much has the customer spent in the past, from campaign 12 to campaign 15?
    * old_response_15 : Binary variable (0/1) indicating if the customer reponded for the old campaign
    * old_response_14 : Binary variable (0/1) indicating if the customer reponded for the old campaign
    * old_response_13 : Binary variable (0/1) indicating if the customer reponded for the old campaign
    * old_response_12 : Binary variable (0/1) indicating if the customer reponded for the old campaign
    * old_response_11 : Binary variable (0/1) indicating if the customer reponded for the old campaign
    * cusum_mailers_till15 : Total mailers till campaign 15
    * mailers_in_15 : Mailers mailed in recent past, campaign 15
    * mailers_in_14 : Mailers mailed in recent past, campaign 14
    * PRE2009_SALES : Life-To-Date sales - Year-To-Date-2009 sales
    * PRE2009_TRANSACTIONS : Life-To-Date transactions - Year-To-Date-2009 transactions

## EDA

Upon exploratory data analysis at a univariate level with respect to the response variable 'RESPONSE16', it was found that the variable `BUYER_STATUS` is a strong indicator of the response of a customer. Status of INACTIVE or LAPSED indicate that the customer will have no response to a campaign. This is a straight rule which can be used for any new data in the test dataset. Going forward, any rows containing the levels other than ACTIVE are removed.

```{r echo=FALSE, message=FALSE, warning=FALSE}
read_csv('bstatus.csv') %>% xtabs(~BUYER_STATUS+RESPONSE16,.)
```

## Imputation

There are many variables with missing values in the original dataset. Depending on the nature of the model, NA values may or may not be acceptable. To counter the `NA` values in the dataset, two approaches were taken, at a high level:

1. For numeric variables, the random forest approach in the `mice` package is used, with a repeated imputation of `m=5`. The resulting imputation densities are very close to the original densities. Refer to [figure](#impute_num). A comparison of the blue and red curves show similar curves.
1. For categorical variables, a similar approach was attempted. Various techniques (randomforest, pmm, cart or mean) were attempted, however, I was not succesful in completing this imputation, due to memory & computation constraints of the machine I have. As a result, to simplify the computation, I have two strategies:
  - For levels which contain "U" or "Unknown", the `NA` are recoded to "U"
  - For levels which do not contain "U", `NA` are recoded to "U"

## Data Splits

There are two types of data splits conducted:

1. *Train + Test Split for Modeling:* The variable `LEARNING_TEST` in the dataset consisted of two levels (LEARNING, TESTING) which were both stratified for the response variable. This was used to generate the split.

1. *Train + Calibration + Test for Variable Selection:* The training split above is further split into a 70-30 stratified split on the reponse variable into a train & calibration dataset. These splits are only used to select and validate the initial set of variables using the techniques described below. Once the variables are defined, the train+test split described above are used for model building & validation.

## Initial Variable Selection

The initial challenge of this problem was to reduce the number of variables from 544 to a more manageable number. Two approaches were attempted:

1. The variables were surveyed manually and using subject matter expertize (names of the variables, descriptions and thus a derived estimation of usefulness), ~120 variables are selected. A set of models is build using these 120 variables. Based on the variable importance plots, these are reduced to ~50 odd variables. The top 5-10 variables from this approach were noted down.
1. Approach two involved utilizing math to reduce the number of variables. The approach followed is described in Zumel & Mount (2014, pg 118 - 122). It involves building a series of single-variable models on the training set (Y ~ Var1, Y~Var2,... Y~VarN). For each model, the AUC on the training set, and the AUC for the calibration set is calculated. The top 20-25 rank ordered calibration-AUC values are selected from each variable types. These are taken into the more detailed analysis. The top 6 variables from each type are shwon below, with their AUC scores. The [appendix](#auc) has graphs showing the comparison of the training and calibration AUC scores; for the categoricals we can see that there are certain variables have a high training score but a low calibration score. In addition to these variables, the manually selected variables from approach 1 are appended.

```{r echo=FALSE, message=FALSE, warning=FALSE}
read_csv('search_nums.csv') %>% head(6) %>% knitr::kable(digits = 3, align = 'c', caption = 'Search across numerical variables')
read_csv('search_cats.csv') %>% head(6) %>% knitr::kable(digits = 3, align = 'c', caption = 'Search across categorical variables')
```

# Model Approach

The package `caret` is used for all the modeling efforts. This package offers a unified interface to over 200 modeling packages. In addition to this, it offers convinient wrappers to perform cross validation, performance metrics extraction and plotting. In total, three models are attempted:

- Randomforest using the `randomForest` package. [Also attempted was the `parRF` which solves random forest in a parallel multi-core approach.]
- SVM
- Naive Bayes

For each model, different pre-processing steps are testing, which include (but not limited to) centering & scaling variables, YeoJohnson transformation, PCA etc. For each model, tuneable hyperparamters (like `mtry` for randomForests) are selected using 10-fold cross validation on the training dataset, while trying to maximize the ROC AUC value.

## Random Forests

The `randomForest` package within `caret` was used to fit multiple models. 

## Naive Bayes

Naive bayes models are fit from the `klaR` package which allow for 3 tunable parameters. `fL` (Laplace Correction), `usekernel` (Distribution Type: gaussian / nonparametric), `adjust` (Bandwidth Adjustment).

## Neural Networks

The `avnnet` package,  Ripley (1996), fits the same neural network model using different random number seeds. All the resulting models are used for prediction. For classification, the model scores are
first averaged, then translated to predicted classes. Bagging can also be used to create the models. 

# Modeling Results

# Customer Scoring

# Final Recommendation to STC

\newpage

# Appendix

#### Missingness maps {#missmap}

```{r echo=FALSE, out.width='80%'}
knitr::include_graphics('images/cat_missmap.png') 
knitr::include_graphics('images/num_missmap.png') 
```

 
#### Numerical variables imputation results {#impute_num}
 
```{r echo=FALSE, out.width='80%'}
knitr::include_graphics('images/report_mice_num.png') 
```

#### AUC results {#auc}
 
```{r echo=FALSE, out.width='80%'}
knitr::include_graphics('catvar_auc.png')
knitr::include_graphics('numvar_auc.png') 
```

\newpage

# Code

```{r eval=FALSE, message=FALSE, warning=FALSE, include=TRUE, paged.print=FALSE}
```